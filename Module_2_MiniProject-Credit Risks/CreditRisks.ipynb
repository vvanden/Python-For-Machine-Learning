{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2\n",
    "Reading the Dataset\n",
    "Read the dataset into the Pandas DataFrame!\n",
    "Does the dataset include any missing values? If so, drop them!\n",
    "Hint: Pandas can do that with one line of code!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"dataset_31_credit-g.csv\").dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Steap 3\n",
    "Feature Selection\n",
    "Choose the features you think are relevant to our analysis! There are A LOT of features in this dataset, but we have to make our models training time reasonable for you.\n",
    "You MUST include at least four (4) numeric features and at least three (3) nominal features. You can choose more if you prefer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Nominal:\n",
    "#For KNN, look for features that have a significant correlation with the target variable,\n",
    "# but are not too closely correlated with each other (to avoid multicollinearity).\n",
    "\n",
    "numeric = df[[\"credit_amount\", \"duration\", \"existing_credits\", \"age\"]]\n",
    "nominal = df[[\"checking_status\", \"credit_history\", \"savings_status\", \"employment\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 4\n",
    "Preprocessing\n",
    "Perform any needed preprocessing on the chosen features, including:\n",
    "Scaling [X]\n",
    "Encoding [X]\n",
    "Dealing with NaN values [X]\n",
    "Note:\n",
    "Use only the preprocessing steps you think are useful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are no NaN values in the dataframe.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#scaling numeric features\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "numeric = scaler.fit_transform(numeric)\n",
    "\n",
    "#convert back to pandas dataframe (from numpy)\n",
    "numeric = pd.DataFrame(numeric)\n",
    "\n",
    "#one-hot encode categorical (nominal) features, drop original column\n",
    "nominal = pd.get_dummies(nominal)\n",
    "\n",
    "#combine the two dataframes horizontially (axis = 1), note: (axis = 0 will combine them vertically)\n",
    "credit = pd.concat([numeric, nominal], axis=1)\n",
    "\n",
    "#check for NaN values in the dataframe\n",
    "if credit.isna().any().any():\n",
    "    print(\"There are NaN values in the dataframe.\")\n",
    "else:\n",
    "    print(\"There are no NaN values in the dataframe.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 5\n",
    "Splitting the Data\n",
    "Split your data as follows:\n",
    "80% training set\n",
    "10% validation set\n",
    "10% test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800 100 100\n"
     ]
    }
   ],
   "source": [
    "# y data (target labels) is the values (.values) from the class \n",
    "y = df[\"class\"].values\n",
    "\n",
    "#grab the number of columns\n",
    "x_columns = len(credit.columns)\n",
    "\n",
    "#x = all the values (.values) rows of the credit dataframe \n",
    "x = credit.iloc[:, 0:x_columns].values\n",
    "\n",
    "#training the model on x and y, 80% for training, 20% for testing (ie: 0.2), random state = 0 for consistant results\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size = 0.2, random_state = 0)\n",
    "\n",
    "#populating X_validate, Y_validate as test set, using 0.5 to keep half for testing\n",
    "X_validate, X_test, y_validate, y_test = train_test_split(X_test, y_test, test_size = 0.5, random_state = 0)\n",
    "\n",
    "#verifying that its split up correctly (800, 100, 100) ie: 80% train, 10% test, 10% validate\n",
    "print(len(X_train), len(X_test), len(X_validate))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 6\n",
    "Training Classifiers\n",
    "Use the KNN-classifier model to train your data. [X]\n",
    "Choose the best k for the k-nearest neighbor (KNN) algorithm by trying different values and validating performance on the validation set. [X]\n",
    "Note: choosing the best k is an example of hyper-parameter tuning.\n",
    "Classification Metrics\n",
    "Print the accuracy score of your final classifier.\n",
    "Print the confusion matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max KNN score:  0.8\n",
      "Max KNN neighbours (index):  20\n"
     ]
    }
   ],
   "source": [
    "#training using KNN\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn = KNeighborsClassifier(n_neighbors=3).fit(X_train, y_train)\n",
    "knn.score(X_test, y_test)\n",
    "\n",
    "#optimizing: run the model in a loop and increment the number of neighbours to see if we can find the optimized amount of nearest neighbours\n",
    "\n",
    "#initizlie the scores array to track the scores\n",
    "scores=[] \n",
    "\n",
    "#the number of neighbours in the test (start with 1 and run up to 39)\n",
    "neighbors = range(1, 40)\n",
    "\n",
    "#use i to test training, rather than a set value of n_neighbours\n",
    "for i in neighbors:\n",
    "    knn = KNeighborsClassifier(n_neighbors=i).fit(X_train, y_train)\n",
    "    results = knn.score(X_test, y_test)\n",
    "    scores.append(results)\n",
    "\n",
    "# Find the maximum value in the list\n",
    "max_value = max(scores)\n",
    "\n",
    "# Find the index of the maximum value in the list\n",
    "max_index = scores.index(max_value)\n",
    "\n",
    "print(\"Max KNN score: \", max_value)\n",
    "print(\"Max KNN neighbours (index): \", max_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "#run the best model\n",
    "knn = KNeighborsClassifier(n_neighbors=max_index).fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy score:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 0.76\n"
     ]
    }
   ],
   "source": [
    "#run the result on the validate set to ensure the score holds with data it has not seen (as 13 was chosed based on test data)\n",
    "result = knn.score(X_validate, y_validate)\n",
    "print(\"Accuracy =\", result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Confusion matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix: \n",
      " [[10 19]\n",
      " [ 5 66]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "#knn is the updated model\n",
    "predictions = knn.predict(X_validate)\n",
    "\n",
    "print(\"Confusion Matrix: \\n\",confusion_matrix(y_validate, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 7\n",
    "Challenge Yourself (Optional)\n",
    "Choose another model (other than k-nearest neighbor (KNN)) and repeat step 6."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.73\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier \n",
    "model = RandomForestClassifier(n_estimators=100,criterion=\"gini\").fit(X_train, y_train)\n",
    "results = model.score(X_test,y_test)\n",
    "\n",
    "print(results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.11 64-bit (microsoft store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f1beb742728b8755f50246d67aee65e2fe2541c1f205e01e33478bc7b87afcd7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
